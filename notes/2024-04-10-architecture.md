# architecture

* question
* retriever: bm25, encoder, vector search - returns ranked results
* retriever can add context from documents, paragraphs, etc.
* generator: llm writes text

Important to really find relevant context from user question.

* relevent docs per classic search or embeddings
* data pipeline task; vs ML task; no matrix number crunching, no loss, eval, etc.
